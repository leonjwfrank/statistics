{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-4-dd38e596e6eb>, line 6)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-dd38e596e6eb>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(f'rand:{x})\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.Tensor(5, 3)  # 构造一个未初始化的5*3的矩阵\n",
    "print(f'Tensor:{x}')\n",
    "x = torch.rand(5, 3)  # 构造一个随机初始化的矩阵\n",
    "print(f'rand:{x})\n",
    "# 此处在notebook中输出x的值来查看具体的x内容\n",
    "print(f'size:{x.size()}')\n",
    "\n",
    "#NOTE: torch.Size 事实上是一个tuple, 所以其支持相关的操作*\n",
    "y = torch.rand(5, 3)\n",
    "print(f'torch rand 53 y:{y}')\n",
    "#此处 将两个同形矩阵相加有两种语法结构\n",
    "x + y # 语法一\n",
    "z = torch.add(x, y) # 语法二\n",
    "print(f'torch add:{z}')\n",
    "\n",
    "# 另外输出tensor也有两种写法\n",
    "result = torch.Tensor(5, 3) # 语法一\n",
    "torch.add(x, y, out=result) # 语法二\n",
    "y.add_(x) # 将y与x相加\n",
    "print(f'把x添加到y中:{y}')\n",
    "# 特别注明：任何可以改变tensor内容的操作都会在方法名后加一个下划线'_'\n",
    "# 例如：x.copy_(y), x.t_(), 这俩都会改变x的值。\n",
    "\n",
    "#另外python中的切片操作也是资次的。\n",
    "print(x)\n",
    "print(x[:,1])#这一操作会输出x矩阵的第二列的所有值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修改前的a tensor([1., 1., 1., 1., 1.]) \n",
      " [1. 1. 1. 1. 1.]\n",
      "add_ 1 修改后的a:tensor([2., 2., 2., 2., 2.])\n",
      "同时b也被修改:[2. 2. 2. 2. 2.]\n",
      "numpy a:[2. 2. 2. 2. 2.]\n",
      "torch b:tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "x:tensor([[0.3222, 0.0975, 0.2033],\n",
      "        [0.1564, 0.3884, 0.3813],\n",
      "        [0.9382, 0.6598, 0.4227],\n",
      "        [0.5390, 0.3094, 0.3635],\n",
      "        [0.0330, 0.6243, 0.3984]])\n",
      "y:tensor([[1.1796, 1.0717, 0.8452],\n",
      "        [1.0343, 0.9335, 1.2545],\n",
      "        [1.7375, 1.5444, 1.0057],\n",
      "        [1.0973, 0.3226, 0.9820],\n",
      "        [0.6270, 1.0201, 0.5872]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 与 numpy 的类型转换\n",
    "# 此处演示tensor和numpy数据结构的相互转换\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(f'修改前的a {a} \\n {b}')\n",
    "# 此处演示当修改numpy数组之后,与之相关联的tensor也会相应的被修改\n",
    "a.add_(1)\n",
    "print(f'add_ 1 修改后的a:{a}')\n",
    "print(f'同时b也被修改:{b}')\n",
    "\n",
    "# 将numpy的Array转换为torch的Tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(f'numpy a:{a}')\n",
    "print(f'torch b:{b}')\n",
    "\n",
    "# 另外除了CharTensor之外，所有的tensor都可以在CPU运算和GPU运算之间相互转换\n",
    "# 使用CUDA函数来将Tensor移动到GPU上\n",
    "# 当CUDA可用时会进行GPU的运算\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y\n",
    "print(f'x:{x}')\n",
    "print(f'y:{y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True), \n",
      " y:tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "z mean out:27.0\n",
      "None\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "x:tensor([ 1.3697, -1.6832,  0.3149])\n",
      "自动求导 x:tensor([ 1.3697, -1.6832,  0.3149], requires_grad=True)\n",
      "自动求导*2 y:tensor([ 2.7394, -3.3664,  0.6297], grad_fn=<MulBackward0>)\n",
      "gradients:tensor([1.0000e-01, 1.0000e+00, 1.0000e-04])\n",
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 中所有的神经网络都来自于autograd包\n",
    "# autograd 是自动求导的意思\n",
    "\n",
    "from torch.autograd import Variable    # PyTorch 最核心的类 Variable\n",
    "x = Variable(torch.ones(2, 2), requires_grad = True)\n",
    "y = x + 2\n",
    "print(f'x:{x}, \\n y:{y}')\n",
    "# print(y.creator)\n",
    "\n",
    "# y 是作为一个操作的结果创建的因此y有一个creator \n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(f'z mean out:{out}')\n",
    "# 现在我们来使用反向传播\n",
    "print(out.backward())\n",
    "\n",
    "# out.backward()和操作out.backward(torch.Tensor([1.0]))是等价的\n",
    "# 在此处输出 d(out)/dx\n",
    "print(x.grad)\n",
    "\n",
    "x = torch.randn(3)\n",
    "print(f'x:{x}')\n",
    "x = Variable(x, requires_grad = True)\n",
    "print(f'自动求导 x:{x}')\n",
    "y = x * 2\n",
    "print(f'自动求导*2 y:{y}')\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "print(f'gradients:{gradients}')\n",
    "y.backward(gradients)\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'神经网络的输出结果是这样的\\nNet (\\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\\n  (fc1): Linear (400 -> 120)\\n  (fc2): Linear (120 -> 84)\\n  (fc3): Linear (84 -> 10)\\n)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个前馈深度神经网络\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"仅仅需要定义一个forward函数就可以了，backward会自动地生成。\n",
    "\n",
    "    你可以在forward函数中使用所有的Tensor中的操作。\n",
    "\n",
    "    模型中可学习的参数会由net.parameters()返回。\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "'''神经网络的输出结果是这样的\n",
    "Net (\n",
    "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear (400 -> 120)\n",
    "  (fc2): Linear (120 -> 84)\n",
    "  (fc3): Linear (84 -> 10)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len params:10\n",
      "params size:torch.Size([6, 1, 5, 5])\n",
      "out 1:tensor([[ 0.1054, -0.0303, -0.0447,  0.0809, -0.1444,  0.0978,  0.0502, -0.0252,\n",
      "          0.0375, -0.0097]], grad_fn=<AddmmBackward>)\n",
      "out:tensor([[ 0.1054, -0.0303, -0.0447,  0.0809, -0.1444,  0.0978,  0.0502, -0.0252,\n",
      "          0.0375, -0.0097]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(f'len params:{len(params)}')\n",
    "print(f'params size:{params[0].size()}') # conv1's .weight\n",
    "\n",
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "out = net(input)\n",
    "print(f'out 1:{out}')\n",
    "'''out 的输出结果如下\n",
    "Variable containing:\n",
    "-0.0158 -0.0682 -0.1239 -0.0136 -0.0645  0.0107 -0.0230 -0.0085  0.1172 -0.0393\n",
    "[torch.FloatTensor of size 1x10]\n",
    "'''\n",
    "\n",
    "net.zero_grad() # 对所有的参数的梯度缓冲区进行归零\n",
    "out.backward(torch.randn(1, 10)) # 使用随机的梯度进行反向传播\n",
    "print(f'out:{out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失值:38.40768814086914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'loss的值如下\\nVariable containing:\\n 38.5849\\n[torch.FloatTensor of size 1]\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = Variable(torch.range(1, 10))  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "\"\"\"loss 计算流程图 input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n",
    "      -> view -> linear -> relu -> linear -> relu -> linear \n",
    "      -> MSELoss\n",
    "      -> loss\"\"\"\n",
    "print(f'损失值:{loss}')\n",
    "'''loss的值如下\n",
    "Variable containing:\n",
    " 38.5849\n",
    "[torch.FloatTensor of size 1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0117,  0.0936,  0.0021, -0.0919,  0.0471,  0.0298])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 这些步骤的输出结果如下\\nconv1.bias.grad before backward\\nVariable containing:\\n 0\\n 0\\n 0\\n 0\\n 0\\n 0\\n[torch.FloatTensor of size 6]\\n\\nconv1.bias.grad after backward\\nVariable containing:\\n 0.0346\\n-0.0141\\n 0.0544\\n-0.1224\\n-0.1677\\n 0.0908\\n[torch.FloatTensor of size 6]\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 代价函数，损失函数的使用 Relu \n",
    "# For illustration, let us follow a few steps backward\n",
    "'''\n",
    "print(loss.creator) # MSELoss\n",
    "print(loss.creator.previous_functions[0][0]) # Linear\n",
    "print(loss.creator.previous_functions[0][0].previous_functions[0][0]) # ReLU\n",
    "'''\n",
    "\n",
    "'''\n",
    "<torch.nn._functions.thnn.auto.MSELoss object at 0x7fe8102dd7c8>\n",
    "<torch.nn._functions.linear.Linear object at 0x7fe8102dd708>\n",
    "<torch.nn._functions.thnn.auto.Threshold object at 0x7fe8102dd648>\n",
    "'''\n",
    "\n",
    "# 现在我们应当调用loss.backward(), 之后来看看 conv1's在进行反馈之后的偏置梯度如何\n",
    "net.zero_grad() # 归零操作\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "''' 这些步骤的输出结果如下\n",
    "conv1.bias.grad before backward\n",
    "Variable containing:\n",
    " 0\n",
    " 0\n",
    " 0\n",
    " 0\n",
    " 0\n",
    " 0\n",
    "[torch.FloatTensor of size 6]\n",
    "\n",
    "conv1.bias.grad after backward\n",
    "Variable containing:\n",
    " 0.0346\n",
    "-0.0141\n",
    " 0.0544\n",
    "-0.1224\n",
    "-0.1677\n",
    " 0.0908\n",
    "[torch.FloatTensor of size 6]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:36.02983093261719, \n",
      " optimizer:SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 权重的使用\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "    \n",
    "# 然而在你使用神经网络的时候你想要使用不同种类的方法诸如：SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
    "import torch.optim as optim\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad() # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # Does the update\n",
    "print(f'loss:{loss}, \\n optimizer:{optimizer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据的加载和使用\n",
    "# 通常来讲，当你处理图像，声音，文本，视频时需要使用python中其他独立的包来将他们转换为numpy中的数组，之后再转换为torch.*Tensor\n",
    "# 图像的话，可以用Pillow, OpenCV。\n",
    "# 声音处理可以用scipy和librosa。\n",
    "# 文本的处理使用原生Python或者Cython以及NLTK和SpaCy都可以。\n",
    "# 图像，我们有torchvision这个包可用,其中包含了一些现成的数据集如：Imagenet, CIFAR10, MNIST等等。同时还有一些转换图像用的工具。 这非常的方便并且避免了写样板代码。\n",
    "\n",
    "# 这里使用CIFAR10数据集。 我们要进行的分类的类别有：'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'。 这个数据集中的图像都是3通道，32x32像素的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Failed download. Trying https -> http instead. Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "classes:('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'注：这一部分需要下载部分数据集 因此速度可能会有一些慢 同时你会看到这样的输出\\n\\nDownloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\\nExtracting tar file\\nDone!\\nFiles already downloaded and verified\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实验 图片分类\n",
    "# 步骤\n",
    "\"\"\"使用torchvision来读取并预处理CIFAR10数据集\n",
    "定义一个卷积神经网络\n",
    "定义一个代价函数\n",
    "在神经网络中训练训练集数据\n",
    "使用测试集数据测试神经网络\"\"\"\n",
    "# 1,读取数据\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# torchvision数据集的输出是在[0, 1]范围内的PILImage图片。\n",
    "# 我们此处使用归一化的方法将其转化为Tensor，数据范围为[-1, 1]\n",
    "\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, \n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(f'classes:{classes}')\n",
    "'''注：这一部分需要下载部分数据集 因此速度可能会有一些慢 同时你会看到这样的输出\n",
    "\n",
    "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
    "Extracting tar file\n",
    "Done!\n",
    "Files already downloaded and verified\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/storage.py\", line 128, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: error executing torch_shm_manager at \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/bin/torch_shm_manager\" at ../torch/lib/libshm/core.cpp:99\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5a2b6e3463f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# show some random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 79, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/storage.py\", line 128, in _new_shared\n    return cls._new_using_filename(size)\nRuntimeError: error executing torch_shm_manager at \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/bin/torch_shm_manager\" at ../torch/lib/libshm/core.cpp:99\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# 查看下载的图像\n",
    "# functions to show an image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# show some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s'%classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design_Model.xline\r\n",
      "\u001b[34mbase_code\u001b[m\u001b[m/\r\n",
      "\u001b[34mbase_structure\u001b[m\u001b[m/\r\n",
      "cpp_program\r\n",
      "map_structure--wm.pdf\r\n",
      "map_structure.xline\r\n",
      "py_adt_stack.ipynb\r\n",
      "py_build_structure(py实现数据结构).md\r\n",
      "py_data_structure.md\r\n",
      "py_data_structure.xline\r\n",
      "py_debug_design_mode.xline\r\n",
      "py_end_expression.py\r\n",
      "py_scientific_computing(建模).md\r\n"
     ]
    }
   ],
   "source": [
    "ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个神经网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool  = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义代价函数和优化器\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练网络\n",
    "for epoch in range(2): # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试训练结果\n",
    "# 通过对比神经网络给出的分类和已知的类别结果，可以得出正确与否，如果预测的正确，我们可以将样本加入正确预测的结果的列表中。\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images  查看已知分类\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s'%classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练的模型如何看待 已知分类\n",
    "outputs = net(Variable(images))\n",
    "\n",
    "# the outputs are energies for the 10 classes. \n",
    "# Higher the energy for a class, the more the network \n",
    "# thinks that the image is of the particular class\n",
    "\n",
    "# So, let's get the index of the highest energy\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s'% classes[predicted[j][0]] for j in range(4)))\n",
    "\n",
    "'''输出结果为\n",
    "Predicted:    cat plane   car plane\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型在整个数据集的表现\n",
    "# 看上去这玩意输出的结果比随机整的要好，随机选择的话从十个中选择一个出来，准确率大概只有10%。看上去神经网络学到了点东西。\n",
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "'''输出结果为\n",
    "Accuracy of the network on the 10000 test images: 54 %\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  全部数据集的准确率\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "'''输出结果为\n",
    "Accuracy of plane : 73 %\n",
    "Accuracy of   car : 70 %\n",
    "Accuracy of  bird : 52 %\n",
    "Accuracy of   cat : 27 %\n",
    "Accuracy of  deer : 34 %\n",
    "Accuracy of   dog : 37 %\n",
    "Accuracy of  frog : 62 %\n",
    "Accuracy of horse : 72 %\n",
    "Accuracy of  ship : 64 %\n",
    "Accuracy of truck : 53 %\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在GPU训练\n",
    "net.cuda()\n",
    "\n",
    "'''输出结果为\n",
    "Net (\n",
    "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear (400 -> 120)\n",
    "  (fc2): Linear (120 -> 84)\n",
    "  (fc3): Linear (84 -> 10)\n",
    ")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())    # 每一步都需要把输入和目标传给GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为神经网络实在太小了，其中的差距并不明显 ， 没有进行CPU运算和GPU运算速度的对比"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
